{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788a08a6-34bb-457d-9e71-76b1a6038e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:25:32.736477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-29 18:25:33.257731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "#import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "from transformers import GPT2Tokenizer,GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "#import huggingface_hub\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b90efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(10).to('cuda:0')\n",
    "b = torch.randn(10).to(a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec5558e-29e1-4b3b-ae64-c6413ce58eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = pd.read_csv('seinfeld_data/scripts.csv')\n",
    "scripts['line'] = scripts.Character + ': ' + scripts.Dialogue\n",
    "#scripts.line[-1:] = scripts.line[-1:]  + ' <|endoftext|>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6106f167-9fde-45ad-adde-7261567d77dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines[item]\n\u001b[0;32m---> 21\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mseinfeld_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscripts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt2_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mseinfeld_lines.__init__\u001b[0;34m(self, control_code, truncate, gpt2_type, max_length)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m scripts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontrol_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     ))               \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m truncate:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines[:\u001b[38;5;241m20000\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/series.py:1594\u001b[0m, in \u001b[0;36mSeries.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;124;03mReturn a string representation for a particular Series.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m repr_params \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mget_series_repr_params()\n\u001b[0;32m-> 1594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepr_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/series.py:1675\u001b[0m, in \u001b[0;36mSeries.to_string\u001b[0;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows, min_rows)\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_string\u001b[39m(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1630\u001b[0m     buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     min_rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1640\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;124;03m    Render a string representation of the Series.\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;124;03m        String representation of Series if ``buf=None``, otherwise None.\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43mfmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeriesFormatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m     result \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mto_string()\n\u001b[1;32m   1689\u001b[0m     \u001b[38;5;66;03m# catch contract violations\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/formats/format.py:299\u001b[0m, in \u001b[0;36mSeriesFormatter.__init__\u001b[0;34m(self, series, buf, length, header, index, na_rep, name, float_format, dtype, max_rows, min_rows)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj \u001b[38;5;241m=\u001b[39m get_adjustment()\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chk_truncate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/formats/format.py:321\u001b[0m, in \u001b[0;36mSeriesFormatter._chk_truncate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m         row_num \u001b[38;5;241m=\u001b[39m max_rows \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 321\u001b[0m         series \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mrow_num\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtr_row_num \u001b[38;5;241m=\u001b[39m row_num\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/reshape/concat.py:563\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_new_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/reshape/concat.py:633\u001b[0m, in \u001b[0;36m_Concatenator._get_new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[1;32m    632\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[1;32m    636\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/reshape/concat.py:634\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[1;32m    632\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 634\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[1;32m    636\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/reshape/concat.py:691\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevels supported only when keys is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 691\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m \u001b[43m_concat_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _make_concat_multiindex(\n\u001b[1;32m    694\u001b[0m         indexes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m    695\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/reshape/concat.py:709\u001b[0m, in \u001b[0;36m_concat_indexes\u001b[0;34m(indexes)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concat_indexes\u001b[39m(indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m--> 709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/indexes/base.py:5405\u001b[0m, in \u001b[0;36mIndex.append\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   5402\u001b[0m names \u001b[38;5;241m=\u001b[39m {obj\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m to_concat}\n\u001b[1;32m   5403\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m-> 5405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/core/indexes/range.py:930\u001b[0m, in \u001b[0;36mRangeIndex._concat\u001b[0;34m(self, indexes, name)\u001b[0m\n\u001b[1;32m    926\u001b[0m non_consecutive \u001b[38;5;241m=\u001b[39m (step \u001b[38;5;241m!=\u001b[39m rng\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rng) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    927\u001b[0m     next_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m rng\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m!=\u001b[39m next_\n\u001b[1;32m    928\u001b[0m )\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m non_consecutive:\n\u001b[0;32m--> 930\u001b[0m     result \u001b[38;5;241m=\u001b[39m Int64Index(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrng_indexes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrename(name)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class seinfeld_lines(Dataset):  \n",
    "    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n",
    "\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
    "        self.lines = []\n",
    "\n",
    "        for row in scripts['line']:\n",
    "          self.lines.append(torch.tensor(\n",
    "                self.tokenizer.encode(f\"<|{control_code}|>{row}<|endoftext|>\")\n",
    "            ))               \n",
    "        if truncate:\n",
    "            self.lines = self.lines[:20000]\n",
    "        self.lines_count = len(self.lines)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.lines_count\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.lines[item]\n",
    "    \n",
    "dataset = seinfeld_lines(scripts['line'], truncate=True, gpt2_type=\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474c1d6-32b1-4e1d-85e5-037f4113ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.line.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db33f99-6e44-4060-865d-dfecdac0cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.line = scripts.line.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b7c98-b872-4be2-a193-d8da9e5100ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'fine_tuning_run_1'\n",
    "model_size = '124M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3597c22-f781-43ac-8fe9-e05c816ce03c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripts[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5457159-c753-417b-84a6-5ccb628102f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2',padding_side='left')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
    "    if packed_tensor is None:\n",
    "        return new_tensor, True, None\n",
    "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
    "        return packed_tensor, False, new_tensor\n",
    "    else:\n",
    "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
    "        return packed_tensor, True, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e095689-c7bb-46cd-997c-27e63cc8dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    dataset, model, tokenizer,\n",
    "    batch_size=16, epochs=3, lr=2e-5,\n",
    "    max_seq_len=400, warmup_steps=200,\n",
    "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "    test_mode=False,save_model_on_epoch=False,\n",
    "):\n",
    "    acc_steps = 100\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train().cuda()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    loss=0\n",
    "    accumulating_batch_count = 0\n",
    "    input_tensor = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Training epoch {epoch}\")\n",
    "        print(loss)\n",
    "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
    "\n",
    "            if carry_on and idx != len(train_dataloader) - 1:\n",
    "                continue\n",
    "\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            outputs = model(input_tensor, labels=input_tensor)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "\n",
    "            if (accumulating_batch_count % batch_size) == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                model.zero_grad()\n",
    "\n",
    "            accumulating_batch_count += 1\n",
    "        if save_model_on_epoch:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893aff91-a669-47a2-880d-443d27034ee0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = train(dataset, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b74b4a-4bed-408a-8e76-fe261a9a7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    entry_count=1,\n",
    "    entry_length=100, #maximum number of words\n",
    "    top_p=0.9,\n",
    "    temperature=.75,\n",
    "):\n",
    "    model.eval()\n",
    "    generated_num = 0\n",
    "    generated_list = []\n",
    "\n",
    "    filter_value = -float(\"Inf\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for entry_idx in trange(entry_count):\n",
    "\n",
    "            entry_finished = False\n",
    "            generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "\n",
    "            for i in range(entry_length):\n",
    "                outputs = model(generated, labels=generated)\n",
    "                loss, logits = outputs[:2]\n",
    "                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
    "\n",
    "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "                sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[\n",
    "                    ..., :-1\n",
    "                ].clone()\n",
    "                sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "                logits[:, indices_to_remove] = filter_value\n",
    "\n",
    "                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
    "                generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n",
    "                    entry_finished = True\n",
    "\n",
    "                if entry_finished:\n",
    "\n",
    "                    generated_num = generated_num + 1\n",
    "\n",
    "                    output_list = list(generated.squeeze().numpy())\n",
    "                    output_text = tokenizer.decode(output_list)\n",
    "                    generated_list.append(output_text)\n",
    "                    break\n",
    "            \n",
    "            if not entry_finished:\n",
    "              output_list = list(generated.squeeze().numpy())\n",
    "              output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n",
    "              generated_list.append(output_text)\n",
    "                \n",
    "    return generated_list\n",
    "\n",
    "#Function to generate multiple sentences. Test data should be a dataframe\n",
    "def text_generation(test_data):\n",
    "  generated_lines = []\n",
    "  for i in range(len(test_data)):\n",
    "    x = generate(model.to('cuda:0'), tokenizer, test_data['Character'][i], entry_count=1)\n",
    "    generated_lines.append(x)\n",
    "  return generated_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf2ec0-2706-40a5-822e-43cd5bf84d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the functions to generate the lines\n",
    "jerry = scripts[scripts.Character=='JERRY'].reset_index()\n",
    "george = scripts[scripts.Character=='GEORGE'].reset_index()\n",
    "elaine = scripts[scripts.Character=='ELAINE'].reset_index()\n",
    "kramer = scripts[scripts.Character=='KRAMER'].reset_index(),\n",
    "frank = scripts[scripts.Character=='FRANK'].reset_index()\n",
    "newman = scripts[scripts.Character=='NEWMAN'].reset_index()\n",
    "estelle = scripts[scripts.Character=='ESTELLE'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33adbe70-3d52-4f85-b620-434eee45d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "george_elaine=[]\n",
    "george_elaine.append(generate(model,tokenizer,prompt='Elaine: (to George) have you tried the new dating app that matches you with other people who'))\n",
    "george_elaine.append(generate(model, tokenizer, prompt=\"George: it didnt work because\"))\n",
    "print(george_elaine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421b16c-f8ec-490a-821d-bd41d4d21738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the huggingface library\n",
    "#import huggingface\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Preprocess your text data\n",
    "processed_data = scripts['line']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "#train_data, val_data = train_test_split(processed_data, test_size=0.2)\n",
    "\n",
    "# Choose a model architecture and training parameters\n",
    "model_params = {\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-5,\n",
    "    'num_epochs': 1\n",
    "}\n",
    "\n",
    "# Train the model on the training data\n",
    "model.train(processed_data, model_params , tokenizer)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "#val_loss = model.evaluate(val_data)\n",
    "#print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# Generate an entire script for an episode of Seinfeld\n",
    "generated_script = model.generate(\"Generate an entire script for an episode of Seinfeld, set in a coffee shop, featuring Jerry, Elaine, and George.\")\n",
    "print(generated_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58377299-f640-44c9-93ce-aa92dea9a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db7d55-9b5f-45a2-aff2-bdd2a680a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation(estelle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
