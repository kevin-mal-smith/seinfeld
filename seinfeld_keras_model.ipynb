{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85903ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1bbb64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0b08d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616a4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'corpus.txt'\n",
    "corpus = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c4414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = re.sub(r\"[^a-zA-Z0-9 .,\\[\\]\\(\\)\\n\\']\", \"\",corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b5dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 unique characters\n",
      "Length of text: 3211598 characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(corpus))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "print(f'Length of text: {len(corpus)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f254d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:27:16.293469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 18:27:16.293642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 18:27:16.293738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 18:27:16.785355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 18:27:16.785506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 18:27:16.785607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-29 18:27:16.785690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "device = tf.device('CUDA') \n",
    "\n",
    "chars = tf.strings.unicode_split(vocab, input_encoding='UTF-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c346f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f506175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a17e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars = chars_from_ids(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a24db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d63e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(corpus, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e0533a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"'JERRY Do you know what this is all about Do you know, why were here To be out, this is out...and ou\"\n",
      "Target: b'JERRY Do you know what this is all about Do you know, why were here To be out, this is out...and out'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:27:17.634116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [3211598]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d849e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be4493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9bbe7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e89e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "739bae12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61992c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:27:17.696636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [3211598]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-29 18:27:17.696861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [3211598]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 71) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:27:20.025420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-29 18:27:20.093809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff76b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5908a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'ask you a question. How many people work at these big law officesMORTY Depends on the firm.JERRY Yea'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"[xvdXcGP[ fyHQs7wV.fF'oTE2T1(KNnVdZ3R412p0 0PVyBt4'iZs1wpvR55,F2uouZo.jA7Y(kMVC7[qHFwUHMLNAWikYlRP5'\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "773b1949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 71)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.264075, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c17e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.099106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90fc3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(), loss=loss)\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './seinfeld_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e200b9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ca77213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:27:20.264127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [3211598]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-29 18:27:20.264381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [3211598]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-29 18:27:20.403363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-29 18:27:20.404057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-29 18:27:20.404692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-29 18:27:20.634331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-29 18:27:20.635167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-29 18:27:20.635795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 20s 37ms/step - loss: 2.1372\n",
      "Epoch 2/5\n",
      "496/496 [==============================] - 19s 37ms/step - loss: 1.4595\n",
      "Epoch 3/5\n",
      "496/496 [==============================] - 19s 37ms/step - loss: 1.3072\n",
      "Epoch 4/5\n",
      "496/496 [==============================] - 19s 37ms/step - loss: 1.2311\n",
      "Epoch 5/5\n",
      "496/496 [==============================] - 19s 37ms/step - loss: 1.1796\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9778f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "    print(skip_ids)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None,mask=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "    \n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    print(predicted_logits)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "    print(predicted_logits)\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "    print(predicted_ids)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "    print(predicted_chars)\n",
    "    print(states)\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e186d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f03adaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"my_model/dense/BiasAdd:0\", shape=(1, None, 71), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(1, 71), dtype=float32)\n",
      "Tensor(\"Squeeze:0\", shape=(1,), dtype=int64)\n",
      "Tensor(\"string_lookup_1/None_Lookup/LookupTableFindV2:0\", shape=(1,), dtype=string)\n",
      "Tensor(\"my_model/gru/PartitionedCall:2\", shape=(1, 1024), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:28:54.982720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-29 18:28:54.983527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-29 18:28:54.984113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b't'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
       " array([[ 0.0964728 , -0.53576314,  0.63929415, ...,  0.17748895,\n",
       "         -0.9191218 ,  0.04077792]], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_step_model.generate_one_step(tf.constant(['Jerry ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95c22b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:28:55.191104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-29 18:28:55.191899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-29 18:28:55.192491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"my_model/dense/BiasAdd:0\", shape=(1, None, 71), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(1, 71), dtype=float32)\n",
      "Tensor(\"Squeeze:0\", shape=(1,), dtype=int64)\n",
      "Tensor(\"string_lookup_1/None_Lookup/LookupTableFindV2:0\", shape=(1,), dtype=string)\n",
      "Tensor(\"my_model/gru/PartitionedCall:2\", shape=(1, 1024), dtype=float32)\n",
      "JERRY: I wish I haven't food, turn you out therejarryuaring him and you have a carDRADE They have together \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.34567832946777344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['JERRY:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0328983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b499a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74d86cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.legacy.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56992094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 18:28:55.978897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-29 18:28:55.979813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-29 18:28:55.980453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-29 18:28:56.312787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-29 18:28:56.313650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-29 18:28:56.314270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 20s 36ms/step - loss: 2.1280\n",
      "Epoch 2/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.4566\n",
      "Epoch 3/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.3049\n",
      "Epoch 4/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2298\n",
      "Epoch 5/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1790\n",
      "Epoch 6/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1382\n",
      "Epoch 7/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1032\n",
      "Epoch 8/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0705\n",
      "Epoch 9/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0394\n",
      "Epoch 10/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0108\n",
      "Epoch 11/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9832\n",
      "Epoch 12/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9580\n",
      "Epoch 13/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9356\n",
      "Epoch 14/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9167\n",
      "Epoch 15/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9003\n",
      "Epoch 16/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8878\n",
      "Epoch 17/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8774\n",
      "Epoch 18/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8692\n",
      "Epoch 19/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8630\n",
      "Epoch 20/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8592\n",
      "Epoch 21/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8570\n",
      "Epoch 22/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8557\n",
      "Epoch 23/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8558\n",
      "Epoch 24/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8567\n",
      "Epoch 25/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8579\n",
      "Epoch 26/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8607\n",
      "Epoch 27/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8643\n",
      "Epoch 28/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8692\n",
      "Epoch 29/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8769\n",
      "Epoch 30/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8805\n",
      "Epoch 31/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8841\n",
      "Epoch 32/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8891\n",
      "Epoch 33/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.8989\n",
      "Epoch 34/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9067\n",
      "Epoch 35/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9162\n",
      "Epoch 36/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9232\n",
      "Epoch 37/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9255\n",
      "Epoch 38/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9342\n",
      "Epoch 39/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9496\n",
      "Epoch 40/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9564\n",
      "Epoch 41/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9761\n",
      "Epoch 42/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9811\n",
      "Epoch 43/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 0.9939\n",
      "Epoch 44/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0069\n",
      "Epoch 45/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0093\n",
      "Epoch 46/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0282\n",
      "Epoch 47/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0363\n",
      "Epoch 48/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0617\n",
      "Epoch 49/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0695\n",
      "Epoch 50/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0677\n",
      "Epoch 51/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.0924\n",
      "Epoch 52/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1124\n",
      "Epoch 53/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1342\n",
      "Epoch 54/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1547\n",
      "Epoch 55/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1675\n",
      "Epoch 56/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2237\n",
      "Epoch 57/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2388\n",
      "Epoch 58/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.3100\n",
      "Epoch 59/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.9723\n",
      "Epoch 60/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8613\n",
      "Epoch 61/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8556\n",
      "Epoch 62/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8417\n",
      "Epoch 63/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8668\n",
      "Epoch 64/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.9043\n",
      "Epoch 65/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8822\n",
      "Epoch 66/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8709\n",
      "Epoch 67/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8483\n",
      "Epoch 68/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8425\n",
      "Epoch 69/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8291\n",
      "Epoch 70/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.8138\n",
      "Epoch 71/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.7880\n",
      "Epoch 72/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.7645\n",
      "Epoch 73/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.7441\n",
      "Epoch 74/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.7206\n",
      "Epoch 75/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.6935\n",
      "Epoch 76/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.6634\n",
      "Epoch 77/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.6333\n",
      "Epoch 78/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.6034\n",
      "Epoch 79/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.5731\n",
      "Epoch 80/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.5429\n",
      "Epoch 81/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.5135\n",
      "Epoch 82/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.4839\n",
      "Epoch 83/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.4552\n",
      "Epoch 84/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.4273\n",
      "Epoch 85/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.4006\n",
      "Epoch 86/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.3753\n",
      "Epoch 87/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.3519\n",
      "Epoch 88/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.3300\n",
      "Epoch 89/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.3113\n",
      "Epoch 90/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2934\n",
      "Epoch 91/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2777\n",
      "Epoch 92/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2634\n",
      "Epoch 93/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2504\n",
      "Epoch 94/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2388\n",
      "Epoch 95/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2269\n",
      "Epoch 96/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2155\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 19s 36ms/step - loss: 1.2055\n",
      "Epoch 98/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1953\n",
      "Epoch 99/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1865\n",
      "Epoch 100/100\n",
      "496/496 [==============================] - 19s 36ms/step - loss: 1.1779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6d0162d00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "591a7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JERRY:GE We still dount O'MR. II'd take the new Joe Mayo Paco.ELAINE Blooding Move good, the onl of the middle of small than mind. I'm sorry I'm so sign anymore, moving the ross. (exits)ELAINE You stood Can't turn youKRAMER (standing) Gimme a see, I'm heading to play gift. We're going to get a Mock's playing a bit of a mail.JERRY Are you excuse meMELISSA Anyway, you said you're the just has a terrible of mine. He couldn't belong for Mr.. You see what you make your celeble. Ok, Kramer, we could try to eat of the few thousandsSUE ELLEN MINUCE (indippiew) Gove. Oh, no. If only strange something or I got no plot for yourself any more finally going more eighty bucket. Too much stand. I'm hating you. Look at this. This is a person was... I want you back there and we were colfered somebody in the first plate, right um... (Jerry room.JERRY You know hawnsELAINE I banged it out tonous moutrs. Viso bullsCLICK I don't like the most of six morning. I Lorge is going on in there I'm gonna take a rise. (starts to fash in antilation with the insideJERRY Ah Kinned toKRAMER I'm so fast. You think it's going to borrow this. They talked toKRAMER Boy, I want to get a subject an' (Jerry is aware of the airport and I put a phone numbers today 'hanged the huma will go love to play for AURA will be s super hereSTETLER 2 Celinial JerusJERRY (As George looks around to the tendon food) MaSter Pete men from my backer[bet Penjustly emotionally playing, uh... you're leaving, Arn't you men international.KRAMER Anyway. All rightJERRY I work hithered you save no hats over like she's going to go.MR. THING TO Jerry, was gonna be fighting.KRAMER our Polarce two menicalGIORGE Sen, I think Jerry is Ten thousand woman at Jerry]ELAINE (Joking around) HuhMICHAE (sury) Must I found him. I had so good.GEORGE But Kair Ladies and Kramer, I'm leaving in George, Punicely is sure it's true.JERRY Assuming If there's a, people  im, put it on get in man in the city for you. (trushing some money) It's about some more an exfect. He has to get everything anymore.GEORGE Well, am I gonna buy a voice syll those with the right to a racket. There  a question of suspicion,  all pretend you should go. Whatley's the being was my tane.ELAINE Would you  to Ninning Besides I'm late.GEORGE Good nice I have to have.JERRY It's much like this.ELAINE You got to put her off Jusies know I gotta get to lever all about even is overhurt, I was just made a good fim is in there and four.JERRY George, I would.BETTE Dairy (cold pathetic) He's luck at his speak It's applese for bystles.JERRY Boy, you have my card. This is Wedeno Skin. That's right, Kramer.WILHELM Do you see thatGEORGE Good. very good. You gotta go with the pagearsJERRY SoupSIDRA Jerry, Huh[Setting Helfican at's soup for you. He was upset...ELAINE Interraes) (Khisal) One's breathing after sixty, no can get out of there.GEORGE ReallyRANK JerryH Let me just be impossible .JERRY What did you give you the booth on (Elaine laughs)KRICER Get out of your father. Have you asked her out when you guys doingGEORGE That was business... I mean, put. Don't you bagens aboutELAINE Aaah I really have money I'm the how Musch guy ... Twelve leans for a whire I get to give it to meet off the excour's head peaces. (George laughs with his enemy party pales) Uh, say I gotta cras.HOLL Did you see thatKRAMER Look, Elferman.FRANK That's a good bock.ELAINE You don't have hot money.KRAMER Oh yes. It's JerryJERRY HelloooohJERRY You mean it still ectensive by 30 destering wood bystering Peterman right Kramer right here JeanPaul, uh, this guy and Jerry's no ones. Try backwards for a bigardiview I still have always been bleakfus.MICK You know, for you going with someone to come back. There is absolutely eating.MR. ROSS GermanFRANK Then you're impossible.GEORGE I never see how it's funny..KRAMER That was try the deal we have. . . . I'm busy in the mather....TIP Boornio's are is commistant.. uh. That was more last night, six wants to put myself on bed it.GEORGE And if there's something wrong my neighbor looking at home. I feel like seeing you for run.JERRY (Rooffie pieces) Look at that. We were just.. get out.AUDREY No, I saw that, they don't unject remimes with the guy is great. Now for.FRANK Helpo something.KRAMER Uhh. Ha, ha ha ha.....ELAINE BBink's more new swap down here.GEORGE Yeah, so engust me finamedial. We're talking.KRAMER Jerry.JERRY Did you just say the time down a plant.JERRY No, you're lucking Subean Street cream at's right here.HELEN All right, ahe your man's sneakers.KRAMER Leg musk good. Vily an in.MR. THOMAGEL Oh, come on, Kramer, um.. was the period of the do look eight. In into a stink.JERRY I don't know how they jump.PUDDY (Starances to the sauna) I wish I dont know look at is nooooooooooooooooooo.... Whish (Showed my street) Cinqy every men.ELAINE When you're steal bilingCLAIRE Oh, my godgie  husanny TodaybookELAINE (singing) please, listen, uh, what d'you have to forgot the victo REW YorkhAND WOMAN It has been pomismiling to bike  years ago, dud.KRAMER Esten kind of car.MR. ROSS I don't remember when she's calling you a little flating your life inside of the guy.GEORGE If I'm standing up very a big due.MR. MERRAN Oh yeah we're back. Ya, you haven't seen dunie as in his deal from prison, buddy. Well, Alright out the kid, what do you should appreciate youKRAMER HuhMOM You remember What're you gonna do this Setting New York Bedies.GUY Maybies and I can make a time of a book. You get home tomorrow. Um. I'm sorry I'm an offccouch the resefficerine life.[Setting New Joe Man Willie, it's Jerry's guy party.PETTY Good is the one who say something 'bout it.GEORGE I fiel it.ATTENDANT Marry, Jerole can JERRY (answering Jew finger, and now, hummmansely was in the car, of course says it had it. Resetts.MR. ROSS (to Morty) Well, look at this place)JERRY Alright., finhed, Elaine. So I had a standy budjer from the Boss balls.ELAINE (Stinks joke and George)  It's like You wear a baby and I'll milk you about The Arthour party.JERRY In thereJERRY To your futurine.MORTY The legs for He's a Dearch.RIDO You want to go this guy, but JoanoooKRAMER Please, yada yada, see, with the fishJERRY Jerry I can speak to you very much.ELAINE You spent a liarge parade of this mird of Christmas call for some strentte.MORTY The Onyway. Beautiful play weekends.CLAIRRY OFFRIE I do for sarcas about to clothing seven forbard everything I would lost my sponen. He was goodlight, ang ya, it's a small pecceppeciable in theatre horminy.JERRY You notice I put this coke down there, third you. What do I sayGEORGE I made a tootebourself a two of yours.PUDDY Just like something.ELAINE Ah, Kramer....CKRAMER Yeah. Tharts for kinda suit. Now lunch is making number off as her pizzable last jar Look at it. (and then to himself) Oh, well... Good morning Dimn's fogurty. But, avenumerating the plane Hey, you know I just have to tell the revolve luck, I got a sense I could change, dressed with her office. The right under the car deformitation there's no one cookie. Newsaffer. It's very good.FRANK NoooooooooooooGEORGE Huh SoGEORGE Wellmit won't be able to get.KRAMER Yeah, they're in the car accentBOWERAMER George. Logsis are you supposed to believe the block day and the platersJERRY Ten years. (Seeing you sensitiving with a size of chip on s) Why do read these slappy Geogge run squareJERRY Ah, well, no we're off the whole ripped person. In fact I chocele a dollar his ways. I feel head) I've been time a spene.HELEN The Hove your houseGEORGE WhatJERRY No, it's me.GEORGE Alright, now I've been having an unboildESTELLE No. She sees you to gi.JERRY What is this A minicESLE KEIN They take a couple acception. Um, you gotta go down to him as fast ramed George has been off guard.NEWMAN All right, by the way I've clean blood Wilhelm What's the difference on Caff is discussinDANNIE MmmGEORGE He wants to tell you this So. I hope I know youre wearing, good twink my hour.SUSAN Ok, I wear one of these books down a flowers there it, eh, you she got to be with the labies.JERRY Ah, Mr. Kramer, this is my CabuJELAINE Because this stuff and these are my schoopFRUGER I would have got to live on the apartment. She says I have asking it on me after a long with his life am DavidJERRY (sincery) Yeah, fine. I'm not .. good for alien, so... I'm sorry that did yver desbery to order you, George.BANIA How's giving down an hour to believe  about the patty Uhoh.JERRY The address whoKERI You put me up for a minuture like this I make sure.FRANK You know, George ends to ask her. Kridless. Morning, wait Will you told me fifty to your heads feelisses in my oil thought. Once you can still want.MRS. CHOATIS Those did get together..[Setting Jerry's spages and they're doing)JERRY So, do you feel us about pathile.JERRY Uh huh.Kramer.KRAMER Oh yeah Yeah, with as fun by Sleepion with the fridge, Kramer, uh. Olight crimes by the door, you know I was just, please, would you make it race real Russyll I've been doing careous people. They're all the fighting time.HELEN I still say it's seeing all the five hooker. You know, I'd like to do to help you.JERRY So you gotte feel your fantassic or whatKRAMER Home bit it was a good for married. Of course I'm gonna say What are you doing told me nowGEORGE I believe she's deligious.JERRY All right, I gonna do somebody seen it.JERRY Well you thunk of a way open the flowing, embarrassing.HELEN Tarr about Flonia hum I was supposed to keep mathroom door. It's key.JERRY You'ruest not.ELAINE Just sleeve you mind is colfetcial who everything.JERRY IKRAMER You too, I'll talk to himself. (Starts back, then) I guess Seinfeld's code for the time.JERRY So chicken some business. Eattriple player sold vitcalled. And I said it was.ELAINE What's this guyGEORGE Whoa WheaherSILVIO Yes, I like to know. He should've been manger. (Jerry ask the plate, starts down That holds them her, and Seinfeld, either teams to the boll George) Yeah, Sup...GEORGE What will to everybody, I've ever seen a covid of ball.JEANY UhHOYT I happened to  \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 23.219468593597412\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['JERRY:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(10000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3da95ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b' '], dtype=object)>,\n",
       " <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
       " array([[-0.60128987,  0.11349986, -0.16860789, ...,  0.17382304,\n",
       "          0.6948192 ,  0.03868974]], dtype=float32)>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_step_model.generate_one_step(tf.constant(['JERRY:']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13330cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8deb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
